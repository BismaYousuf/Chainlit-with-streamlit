This is a simple example demonstrating how to create and run an AI assistant agent using **Chainlit** ğŸ¤–, **OpenAI Async API** ğŸš€, and the **openai-agents** SDK ğŸ› ï¸.

---

## Features âœ¨

- ğŸ” Loads environment variables from `.env`
- ğŸ—ï¸ Uses OpenRouter API key for authentication
- ğŸ¤– Creates an AI agent with specific instructions
- ğŸŒ€ Streams the AI response token-by-token to Chainlit chat UI
- ğŸ‘¥ Maintains agent instance per user session

---

## Prerequisites ğŸ“‹

- ğŸ Python 3.8+
- ğŸ“¦ Install dependencies:

```bash
pip install chainlit openai-agents openai python-dotenv
ğŸ”‘ A valid OpenRouter API key stored in .env file as:

ini
Copy
OPEN_ROUTER_API_KEY=your_api_key_here
How to Run â–¶ï¸
ğŸ“‚ Clone this repo or save your script as main.py.

âš™ï¸ Activate your virtual environment (recommended):

bash
Copy
# Windows
.\\.venv\\Scripts\\activate

# macOS/Linux
source .venv/bin/activate
â–¶ï¸ Run Chainlit app with:

bash
Copy
chainlit run main.py -w
ğŸŒ Open your browser at http://localhost:8000 to interact with the agent.

Code Overview ğŸ“
ğŸ“¥ Loads environment variables via dotenv

ğŸŒ Creates an async OpenAI client with OpenRouter base URL

ğŸ§  Defines an AI Agent with a helpful assistant prompt

ğŸš€ On chat start, the agent instance is stored in user session

ğŸ’¬ On each user message:

ğŸ“¨ A Chainlit message is created and sent immediately with empty content

ğŸ”„ The agent runs asynchronously and streams token responses

âš¡ Tokens are streamed live to the Chainlit message

âœ… Final content updates the message

Notes ğŸ›ï¸
âœ”ï¸ Ensure your OpenRouter API key is valid and has sufficient quota

ğŸ”§ The msg.update() method is used to finalize the message without arguments

ğŸ¯ For streaming token-by-token updates, msg.stream_token() is used

pgsql
Copy
